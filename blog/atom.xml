<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://datacraft-paris.github.io/blog</id>
    <title>datacraft blog Blog</title>
    <updated>2022-02-18T00:00:00.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://datacraft-paris.github.io/blog"/>
    <subtitle>datacraft blog Blog</subtitle>
    <icon>https://datacraft-paris.github.io/img/datacraft_logo.png</icon>
    <entry>
        <title type="html"><![CDATA[Comment veiller à ce que les biais humains n’imprègnent pas les algorithmes ?]]></title>
        <id>biais-humains-et-algorithmes</id>
        <link href="https://datacraft-paris.github.io/blog/biais-humains-et-algorithmes"/>
        <updated>2022-02-18T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Article publié dans Usbek & Rica le 18 février 2022]]></summary>
        <content type="html"><![CDATA[<hr/><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:28px;color:#69337A;padding:1.0em"> Stephanie Lehuger, Thinker et Entrepreneur, membre du <u>club Datacraft</u>, qui réfléchit aux questions éthiques soulevées par l’IA, nous explique dans cette tribune de quels outils et méthodes nous disposons actuellement pour qu’un préjugé humain ne se retrouve pas dans l’algorithme d’une intelligence artificielle.</div></div><p>Tous les humains ont des biais cognitifs, c’est inévitable. Et les data scientists sont des humains, donc ils sont fatalement sujets aux biais, comme tout le monde. Pour établir des connaissances, les data scientists analysent des données. Et ces données, si elles sont mal choisies, donnent de mauvais résultats. Ainsi, un biais cognitif se transforme en biais de donnée qui se transforme ensuite en biais algorithmique.</p><p>On peut dire qu’un algorithme fonctionne comme une recette de cuisine où les ingrédients seraient les données et la recette le code : si les ingrédients (les données) sont de mauvaise qualité, avec des biais par exemple, le résultat ne peut qu’être décevant. La plupart du temps, les biais proviennent des données et cela se produit de deux manières.</p><p>En premier lieu, ils peuvent être le résultat d’une mauvaise collecte. Imaginons par exemple qu’on cherche à déterminer le loyer moyen que paient les gens qui louent leur logement. Si les data scientists sont parisiens et récupèrent la base de données de leur ville, ils vont obtenir un résultat élevé par rapport à la moyenne nationale. Il sera biaisé par les loyers de Paris.</p><p>La transmission d’un biais s’effectue donc au travers des données choisies (la « data »). Si les data scientists n’ont pas conscience que les loyers sont moins élevés dans les villes de taille moyenne et en zone rurale que dans les grandes villes et qu’ils entraînent un algorithme à prédire le prix du loyer sur ces données-là, alors ses prédictions seront biaisées aussi. Le biais d’une IA peut provenir à l’origine d’un biais cognitif humain, qui se transmet dans les données choisies qui sont biaisées, puis elles influencent ensuite les résultats en s’étant transformées en un biais algorithmique.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> S’il existe une discrimination des femmes dans une entreprise, se baser sur les données passées pour évaluer le potentiel d’une candidate, même plus brillante qu’un concurrent masculin, lui sera défavorable</div></div><p>En deuxième lieu, les biais peuvent émaner d’une situation déjà biaisée et qu’un algorithme pourrait amplifier. Comme une intelligence artificielle qui baserait son apprentissage sur des données historiquement biaisées. Si, depuis toujours, il existe une discrimination des femmes dans une entreprise, se baser sur les données passées pour évaluer le potentiel d’une candidate, même plus brillante qu’un concurrent masculin, lui sera défavorable. Si, historiquement, les femmes sont peu représentées, l’algorithme pourra en déduire de manière erronée qu’elles ont un profil moins désirable.</p><h2> Quelques exemples de biais communs </h2><p>Un biais typique qu’il faut tenter d’éviter est le biais des survivants. Par exemple, quand on constate que des bâtiments de plus de cent ans sont encore debout, on a l’impression que la « construction d’antan » était de meilleure qualité qu’aujourd’hui. Pourtant, quand on y réfléchit, la quasi-totalité de ce qui a été construit depuis l’invention de la construction s’est en fait écroulée ou a été démolie, donc ces bâtiments « survivants » sont des exceptions.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Les data scientists doivent éviter le biais du survivant qui consisterait à tirer des conclusions sur la base d’une population incomplète</div></div><p>Lors de l’étude de données par des data scientists, il leur faut éviter le biais du survivant qui consisterait à tirer des conclusions sur la base d’une population incomplète, comportant uniquement les éléments ayant « survécu », qui sont en fait des exceptions, plutôt que des cas représentatifs.</p><p>En France, des « antivax » ont été victimes du paradoxe de Simpson. Ils ont assuré à tort sur les réseaux sociaux que les non-vaccinés ne saturent pas les services de réanimation du pays, en s’appuyant sur des données de la Drees mal interprétées. Leur erreur principale est d’avoir regardé les chiffres bruts au lieu des pourcentages. Il y a en effet neuf fois plus de vaccinés que de non-vaccinés en France. </p><p>Alors que les non-vaccinés sont très minoritaires, ils sont surreprésentés à l’hôpital, avec 63 % des admissions en soins critiques. Si on regarde les chiffres absolus, on peut avoir l’impression que les deux populations sont en nombre équilibrés dans les hôpitaux, mais ce serait oublier de regarder la proportion de chacune dans la population générale. C’est ainsi que plusieurs enquêtes récentes menées sur des échantillons d’hôpitaux ont conclu que les non-vaccinés représentaient entre 70 % et 90 % dans les services de réanimation.</p><h2> Comment les data scientists corrigent les biais ? </h2><p>Une fois qu’on a identifié pourquoi et comment les biais posent un problème aux data scientists, on va s’intéresser à ce que les data scientists font, ne font pas, et devraient faire pour limiter les risques liés à ces biais.</p><h3> 1. Prendre conscience du problème et se poser les bonnes questions </h3><p>Pour prendre conscience du problème des biais cognitifs, les data scientists ont accès à différents types de ressources. Ils peuvent par exemple commencer à s’informer par le biais d’une charte, comme la charte éthique élaborée au sein de datacraft. Ils peuvent par ailleurs analyser le contenu des référentiels d’évaluation de l’IA de confiance, comme celui de Labelia Labs (ex-Substra Foundation) ou celui du LNE. Les serments établissent également une liste pertinente de critères d’une IA responsable, comme le font Tech pledge et Holberton-Turing Oath. Enfin, il existe des outils pratiques comme la checklist de Data Science éthique deon, accessible en ligne de commande.</p><p>Il est important d’avoir un esprit critique sur son propre travail quand on est data scientist. Si on ne devait choisir que 3 questions à se poser absolument, voici ce que je propose :</p><ul><li>S’engager à faire une pause pour s’interroger sur toutes les conséquences de son travail, qu’elles soient voulues ou non;</li><li>Contrôler les conséquences de son travail dans le temps;</li><li>Tendre vers l’autorégulation à l’aide de référentiel d’évaluation, de certification avec audit), en complément des « 7 points de vigilance » soulignés par la Commission européenne.</li></ul><h3> 2. Mesurer les biais </h3><p>Après avoir pris conscience de la potentielle existence de biais, la seconde étape consiste à définir des métriques appropriées afin de les mesurer convenablement. Le choix des métriques dépend alors essentiellement de ce que l’on cherche à contrôler. Aequitas est une boîte à outils open source pour auditer les biais, créée par le Center for Data Science and Public Policy de l’Université de Chicago. </p><p>Elle permet de vérifier les prédictions des outils d’évaluation des risques basés sur l’apprentissage automatique afin de comprendre les différents types de biais et de prendre des décisions éclairées sur le développement et le déploiement de ces systèmes. Le « fairness tree » aide à choisir la bonne métrique. Là comme ailleurs, il convient d’être attentif aux choix réalisés puisqu’il existe un nouveau biais possible. En effet, il faut avoir conscience que, en choisissant une métrique, on écarte toutes les autres.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Tout choix concernant une population étudiée devient moral en data science</div></div><p>Des métriques faciles d’accès pour les data scientists sont également mises en œuvre. Une équipe au sein de datacraft a réalisé une cartographie de 5 « fairness open source libraries » lors d’un benchathon : AIF360, Shapash, Aequitas, What if tool, Fairlearn.</p><p>Tout choix concernant une population étudiée devient moral en data science. En dehors des très grands groupes qui ont conscience des risques réputationnels forts auxquels ils sont soumis s’ils ne font pas attention aux biais et à leurs conséquences, cela reste principalement une question qui tient du ressort individuel dans les autres entreprises.</p><p>Même si ce n’est pas obligatoire légalement, il revient donc aux data scientists d’être moralement critiques sur leurs choix de données. Tout comme il est nécessaire d’être prudent pour ne pas introduire de biais dans les algorithmes qu’ils développent.</p><h3> 3. Limiter les risques de biais </h3><p>Il existe de nombreuses méthodes pour réduire les biais, que l’on peut diviser en trois grandes familles selon que l’intervention du praticien se situe avant, pendant ou après l’entraînement de l’algorithme. Avant l’entraînement, ces méthodes consistent à transformer les données à disposition, par exemple en les repondérant.</p><p>Concrètement, on peut revoir la pondération du nombre de personnes dans un jeu de données pour s’assurer qu’il y a autant d’hommes que de femmes et ainsi éviter un biais de genre. Pendant l’entraînement, il s’agit d’incorporer des contraintes d’équité à satisfaire, en complément des objectifs de performance classique. Enfin, les méthodes dites de post-traitement consistent à modifier les décisions des algorithmes, par exemple en favorisant les sous-groupes discriminés.</p><div style="margin-top:1em;margin-bottom:2em"><div class="warning" style="font-size:24px;color:#69337A;border-left:solid #805AD5 4px;padding:0.7em"> Pour qu’une entreprise soit à la fois juste et profitable, toutes les parties prenantes doivent échanger pour parvenir à des compromis acceptables</div></div><p>En diminuant les biais d’un côté, on diminue généralement la performance des algorithmes de l’autre : on parle du fairness-accuracy tradeoff. Pour qu’une entreprise soit à la fois juste et profitable, toutes les parties prenantes doivent échanger pour parvenir à des compromis acceptables. Les data scientists, les décideurs business ou encore les équipes de gouvernance sont impliqués dans ce processus complexe afin d’aboutir à un arbitrage. Une fois la décision prise, l’algorithme déployé et mis en production, il est indispensable de mettre en place une politique de supervision en temps réel (monitoring) afin de détecter de possibles changements de comportement du modèle.</p><p>Pour résumer, afin d’éviter de transmettre des biais humains à une intelligence artificielle, les data scientists doivent faire preuve d’esprit critique vis-à-vis de leurs possibles préjugés inconscients quand ils sélectionnent leurs données et construisent leurs algorithmes. Il n’y a malheureusement pas de méthode miracle qui marche à tous les coups. Un modèle repose sur des hypothèses dépendantes d’un contexte, elles seront donc différentes pour chaque problème, sans qu’un modèle magique fonctionne pour tous.</p>]]></content>
        <author>
            <name>Stéphanie Lehuger</name>
            <uri>mailto:contact@datacraft.paris</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Few Shot Learning - application de la méthode iPET]]></title>
        <id>draft</id>
        <link href="https://datacraft-paris.github.io/blog/draft"/>
        <updated>2022-02-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Draft of the first blog]]></summary>
        <content type="html"><![CDATA[<p>(<a href="https://numenta.com/blog/2019/08/30/case-for-sparsity-in-neural-networks-part-1-pruning">source</a> de l&#x27;image de présentaion)</p><hr/><h2>Qu’est ce que le Few Shot Learning (FSL) ? - titre alternatif : Sujet du jour : le Few Shot Learning (FSL)</h2><p>Il est bien connu que la puissance des méthodes de Machine Learning supervisées, et plus particulièrement de Deep Learning avec les réseaux de neurones, depuis le début des années 2000, a reposé sur la constitution de <strong>grands jeux de données labellisés</strong>. Deux éléments sont importants ici : ‘grands’ et ‘labellisés’.</p><p>Pour le premier point, ça représente par exemple des milliers, voire des millions d’images pour la Computer Vision et des millions d’ensembles de phrases pour le NLP. Concernant le second point, il signifie qu’au cours de son apprentissage, l’ordinateur compare son évaluation des données avec le label qu’un intervenant humain a associé à chaque donnée.</p><p>Dans le cas du <strong>Few Shot Learning (FSL)</strong>, les chercheurs veulent créer des méthodes capables d’apprendre avec peu de données, i.e. des dizaines ou des centaines, ce qui représente un gain de temps et d’énergie, tout en conservant des performances équivalentes aux modèles traditionnels bien sûr. C’est pourquoi en français on parle d’<strong>apprentissage frugal</strong>. Toutefois, en pratique les méthodes de FSL prennent un modèle traditionnel, pré-entraîné sur un grand nombre de données, et elles le spécialisent sur le cas d’usage via une courte phase d’apprentissage sur le petit jeu de données à disposition ; c’est du fine-tuning. Mais en plus, le Few Shot c’est une méthode qui va au-delà des méthodes traditionnelles, elle permet de faire du semi-supervisé, c’est ce qu’on va voir avec le cas d’usage.</p><h2>Le cas d’usage - titre alternatif : C’est quoi le problème ?!</h2><p>Ekimetrics s’est intéressé à l’apprentissage frugal pour exploiter les énormes jeux de données des petits commentaires quotidiens sur internet, avec une problématique de gain de temps… De la frugalité avec des énormes jeux de données ? On vous explique !</p><p>Mieux que le seul nombre d’étoiles d’un restaurant ou d’un hôtel, il s’agit de prendre en compte les avis dans les tweets, les posts, les brèves… qui sont par essence des données non labellisées et de les exploiter. L’annotation humaine de ces avis est inenvisageable. Ça coûterait trop cher, ça prendrait trop de temps, et il faudrait recommencer tous les jours pour suivre l’évolution du sentiment. En l&#x27;occurrence, pour la recherche d’Ekimetrics, le sujet d’étude porte sur des commentaires de restaurants.</p><p>Mais si la machine était capable d’évaluer les commentaires, à 2 Gigahertz, tout de suite le problème serait réglé. C’est là que le Few Shot, en utilisant la méthode PET, peut devenir utile.</p><p>Dans la suite, nous vous présentons la méthode PET, comment l’utiliser dans le cadre du FSL et enfin, comment Ekimetrics l’utilise sur les avis des consommateurs.</p><h2>PET qu’est ce que c’est ?</h2><p><strong>PET</strong> est l’acronyme de ‘<strong>Pattern Exploiting Training</strong>’. La méthode repose sur un ensemble fixe et prédéfini de <strong>patterns</strong> et de <strong>verbalizers</strong> et un <strong>Pre-trained Language Model</strong> a.k.a. <strong>PLM</strong>. Les patterns sont les phrases à trou (“It was…”, “Just…!”, “All in all, it was…”, “In summary, the restaurant is…”) et les verbalizers sont les mots qui peuvent compléter ces phrases et auxquels sont associées des notes chiffrées. On commence à retrouver les nombres que l’ordinateur aime tant !</p><p>Concrètement, reprenons notre exemple des évaluations des restaurants, la méthode consiste à :</p><ul><li>prendre un commentaire,</li><li>y associer aléatoirement un pattern,</li><li>soumettre le tout au PLM qui va le compléter en choisissant un verbalizer.</li></ul><p><img src="./img/2022-02-04-MindshakeTime/PET.png" alt="image" title="Schema of a basic PET"/>{:.image-left}</p><p>Par exemple (voir Fig. 1), avec le commentaire “Best pizza ever!”, on construit la phrase à trou : “Best pizza ever! It was … .” que le PLM va compléter avec ‘great’ avec une confiance de 0.8, sachant que ce mot est noté +1.</p><h2>FSL + PET : première application aux avis internet</h2><p>Revenons à la masse brute des avis des consommateurs sur internet. <strong>PET est la méthode</strong> pour associer une note à un commentaire, le <strong>FSL est le moyen</strong> de traiter automatiquement tout le jeu de données, et le travail de l’algorithme se fait en deux étapes.</p><p>Dans un premier temps, on labellise un petit nombre de commentaires, une centaine par exemple, ce qui signifie qu’on associe une paire pattern plus verbalizer à ces commentaires, et on finetune le PLM avec cette centaine. Puis, une fois le PLM spécialisé, on le laisse labelliser tout le reste du jeu de données, automatiquement. Ça en fait une méthode semi-supervisée d’analyse de sentiment des commentaires.</p><p>Cependant, cette application basique présente des limites. D’une part, le verbalizer donné par le PLM peut ne pas être le plus adapté au commentaire et, d’autre part, c’est très ambitieux de spécialiser le PLM une fois sur une centaine d’exemples pour ensuite en traiter des dizaines de milliers ou plus. C’est pourquoi les chercheurs ont développé une méthode de distillation qui augmente la robustesse de PET, c’est la méthode <strong>iPET : iterative PET</strong>.</p><h2>i(terative)PET : une méthode de distillation astucieuse</h2><p>Une image peut valoir mille mots…</p><p><img src="./img/2022-02-04-MindshakeTime/iPET.png"/></p><p>… Mais quelques mots seront quand même nécessaires pour expliquer cette image !</p><p>Tout d’abord, le schéma de gauche sur la figure présente l’adaptation de PET qui permet d’obtenir le label le plus adapté au commentaire… en moyenne. En effet, il s’agit ‘simplement’ de <strong>faire travailler des méthodes PET indépendantes en parallèle</strong> (trois sur le schéma). Les trois cellules ont le même PLM au départ, et elles travaillent sur les mêmes commentaires, mais avec des patterns différents. Dans la phase d’entraînement sur les données labellisées, les PLMs se spécialisent différemment. Puis, durant la phase de travail, pour un même commentaire ils produisent des <strong>paires pattern-verbalizers</strong> (appelées <strong>PVPs</strong> sur le schéma) indépendamment les uns des autres ; possiblement les mêmes, mais pas avec les mêmes probas. Enfin, <strong>en sortie</strong> ces (trois) labels sont utilisés pour calculer <strong>un soft-label</strong>, i.e. un <strong>label moyen</strong>.</p><p>Ensuite, sur la droite est présenté le caractère itératif de la méthode iPET. Elle consiste à diviser le jeu labellisés sur plusieurs itérations (indiquées par les exposants allant de 0 à k) et à diviser encore à chaque itération entre plusieurs méthodes parallèles (indiquées par les indices allant de 0 à 4). Mais attention, chacun des quatre modèles ici fait du soft-labelling comme présenté à gauche de la figure, c’est-à-dire qu’ils contiennent plusieurs méthodes en parallèle.</p><p>Donc, si l’on suppose que l’on part pour trois itérations, l’information labellisée est distillée de la manière suivante. À l’itération 0 sur le schéma, on prend un tiers des données labellisées, et on fournit un quart de ces données à chaque modèle pour le finetuner, avant de prendre un tiers des données à labelliser et d’en fournir un quart à chaque modèle pour soft-labellisation. Ce qui constitue la fin de la première itération.</p><p>À la deuxième itération - itération 1 sur le schéma, on commence à nouveau par un phase de fine-tuning, mais avec un jeu de données labellisées constitué pour partie des données annotées par un être humain (le deuxième tiers), et pour partie de données soft-labellisées. Toutefois, on fait attention à ce qu’un modèle ne s’entraîne pas avec des données qu’il a lui-même soft-labellisé, pour éviter qu’il renforce ses biais… on distille ! Par exemple sur le schéma, à l’itération 1, le jeu d’entraînement T fourni au modèle 4, i.e. T14, est constitué de données soft-labellisées par les modèles 1 et 2, en plus des données annotées par l’humain. Puis on prend le deuxième tiers de données à annoter, on en fournit un quart à chaque modèle pour soft-labellisation et on finit la deuxième itération.</p><p>Pour la troisième itération, vous avez compris le principe je pense…   </p><p>À la fin, les millions de commentaires sont plutôt bien soft-labellisés, à la vitesse de la machine et au coût de l’électricité, tout est prêt pour un classifieur sur le schéma d’Ekimetrics et je vous ai expliqué tous les termes entourés sur la figure et présenté toutes les étapes. </p><h2>Avantages, inconvénients, limites et améliorations.</h2><p>Nous avons déjà vu certains des avantages. Internet est une place sur laquelle il y a pléthore d’avis en tout genre : films, restaurants, hôtels, produits de grande consommation, lieux divers… Annoter ces données serait un travail coûteux et sans fin, nous l’avons dit. L’approche iPET permet d’automatiser cette étape, à la vitesse de l’ordinateur et quel que soit le cas d’étude.</p><p>Du point de vue des performances, Ekimetrics a indiqué avoir une précision de 88% avec seulement 50 données labellisées au départ, et même 84% avec 10 données labellisées !! En comparaison, les modèles supervisés peuvent atteindre des précisions de 99%, mais au prix d’un énorme travail de pré-traitement. C’est donc un pas conceptuel de plus dans la réduction de la supervision.</p><p>Toutefois, le domaine d’application se restreint à des données textuelles assez courtes d’une part. Et d’autre part, la charge de travail est déplacée vers une bonne conceptualisation du cas d’étude. Les résultats sont extrêmement dépendants de la formulation des patterns et des choix de verbalizers (i.e. choix du prompting). Ceux-ci impliquent une grande variabilité qui n’est pas maîtrisée. De plus le PLM utilisé - un modèle BERT dans le cas d’Ekimetrics, cache des inconnues sur le corpus qui a servi à son entraînement, son domaine d’applicabilité, ses paramètres. On touche là à une limite dans laquelle l’IA n’est plus tout à fait de l’open science.</p><hr/><h1>Notes de Xavier que je n&#x27;ai pas mises</h1><h2>LIMITES et PISTES D&#x27;AMÉLIORATIONS</h2><p>PLM ou Foundation modèle avec quelles données a-t-il été entraîné ???</p><p>Que donnerait l’utilisation de plusieurs PLM ?</p><p>une amélioration de ces approches est proposé dans le papier <a href="https://arxiv.org/pdf/2103.11955.pdf">https://arxiv.org/pdf/2103.11955.pdf</a>.</p>]]></content>
        <author>
            <name>Kapichu</name>
            <uri>mailto:julien.guyot@datacraft.paris</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[L’artisanat de la science des données avec datacraft]]></title>
        <id>datacraft-binaire</id>
        <link href="https://datacraft-paris.github.io/blog/datacraft-binaire"/>
        <updated>2021-03-23T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Article publié dans binaire le 23/03/2021]]></summary>
        <content type="html"><![CDATA[<p>Cet article a été initialement publié le 23/03/2021 dans <a href="https://www.lemonde.fr/blog/binaire/2021/03/23/lartisanat-de-la-science-des-donnees-avec-datacraft/">binaire</a>, blog créé en janvier 2014 dans le journal <a href="https://www.lemonde.fr/blog/binaire/a-propos/">Le Monde</a> à l’initiative de Serge Abiteboul et de plusieurs collègues de la Société Informatique de France, afin de communiquer sur ce qu’est vraiment l’informatique en tant que science et technique.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Rendre visible les légendes des images.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>L’artisanat de la science des données avec datacraft</h1><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Hiba.png" alt="image" title="**Courteousy of Hiba Kalache, therefore the most profound though is a beating heart (bannière du site de datacraft)**"/>
<strong>il manque une légende pour cette image</strong></p><p><strong>Datacraft</strong>, c’est quoi ce « machin » ? On est à Sorbonne Université <strong>[1]</strong>, dans le Sorbonne Center for Artificial Intelligence, sur le campus de Jussieu, un haut lieu des sciences. Pourtant, ce n’est pas un labo universitaire, même si cela y ressemble. Ça tient du club, un peu du fablab. C’est un espace de cotravail apprenant où on travaille vraiment en commun, plus que dans un espace de cotravail classique. Officiellement, c’est une startup. En fait, ce n’est pas facile à classifier, ce qui est pour moi assez positif dans le monde de la science des données qui se réinvente en permanence.</p><p>J’ai été tenté de dire que c’était un « temple des données » tant les données sont au centre des préoccupations de tous et toutes dans ce lieu. Mais non, les données ne sont pas adorées ici, elles sont questionnées, challengées. On vous parle ici de leur mise au service des entreprises et de la société, de « responsabilité sociale des données ».</p><p>En fait, la vraie valeur, il faut la chercher dans le nom de l’entreprise, datacraft, en français « l’artisanat de la science des données » (traduction personnelle). C’est tellement plus joli qu’en anglais, même si c’est certainement moins vendeur. Avec datacraft, nous sommes bien dans l’artisanat, dans un savoir-faire spécifique, hors contexte industriel de masse. Nous sommes pile poil dans le compagnonnage en sciences des données, dans l’idée de se former en faisant, en échangeant, en bénéficiant de conseils d’experts.</p><p>Je pense qu’un tel compagnonnage est particulièrement bien adapté à la science des données. En 2014, dans un rapport pour le gouvernement <strong>[2]</strong>, nous parlions de la nécessité de booster les formations aux sciences des données, en insistant sur le caractère indispensable de projets « les yeux dans les yeux, de données en vraie grandeur ». Depuis, de telles formations ont vu le jour et les entreprises ont souvent maintenant leurs data scientists. Mais ceux-ci souffrent d’être isolés, de ne pas pouvoir partager leurs questionnements, leurs expériences. L’image du geek qui bosse seul dans son coin est à des kilomètres de la réalité de l’informatique – on travaille le plus souvent en équipe – et tout particulièrement dans la science des données. Un beau projet en science des données met typiquement en jeu des compétences variées que l’on trouve rarement chez une personne unique : gestion de données, big data, machine learning, compétence métier, etc.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/Atelier.png" alt="image" title="**©datacraft, atelier computer vision au service de l’imagerie médicale**"/>
<strong>il manque une légende pour cette image</strong></p><p>Les data scientists des entreprises adhérentes à datacraft peuvent venir travailler dans un espace de cotravail où ils rencontreront des data scientists, leurs homologues d’autres entreprises et des experts résidence. Il ne s’agit pas juste de partager de beaux bureaux et du café.  Ils peuvent par exemple dans des ateliers pratiques échanger des idées, apprendre, et partager. Et ce contexte permet aux idées d’infuser entre des domaines différents.</p><p>Par exemple, datacraft a organisé un atelier avec l’INSEP (l‘Institut national du sport, de l’expertise et de la performance) autour de l’utilisation de données dans le sport de haut niveau. Il s’agissait d’arriver à construire la meilleure équipe selon le contexte, les adversaires, la météo, etc. Il était difficile de prévoir l’intérêt des ingés de Vinci Autoroutes sur ce sujet, pourtant, ils ont apporté une expertise précieuse.</p><p><strong>Image here</strong>
<img src="./img/2021-03-23-binaire/INSEP.png" alt="image" title="**Image: https://pixabay.com/users/clker-free-vector-images-3736/**"/>
<strong>il manque une légende pour cette image</strong></p><p>Pas de bol, datacraft s’est lancée en février 2020, pas le meilleur moment pour un concept basé sur un lieu de rencontre physique. Les membres ont initié des projets autour de la santé et de l’éducation, pour aider la société dans un temps de crise sanitaire grave. Je me serais aussi attendu à ce qu’ils découvrent les avantages considérables du travail à distance, d’une certaine inutilité de la rencontre physique. Pas du tout, Isabelle Hilali, fondatrice et pédégère de datacraft, explique : « Pour moi, la dimension physique est essentielle, et j’aimerais revenir dès que possible au présentiel car il est important de garder du lien. » Et quand j’insiste sur les avantages du distanciel, elle précise : « Il faut aussi le plaisir du travail. Il y a moins de plaisir à collaborer à distance. »</p><p>Quand on met des gens brillants ensemble, les initiatives fleurissent. Des membres se regroupent pour former des consortiums et répondre à des appels à projets ambitieux auxquels ils n’auraient pas les moyens de répondre individuellement. Ils mettent en place des formations, des espaces d’échanges dans des domaines spécifiques comme les ressources humaines ou les aspects légaux des applications de la science des données.</p><p>J’ai parlé de datacraft à des collègues chiliens. Leur réaction : un tel club serait encore plus indispensable au Chili où les data scientists des entreprises sont encore plus isolés qu’en France. Je pense que c’est vrai pour de nombreux pays, datacraft devrait donc s’exporter ? J’ai posé la question : ils ouvrent une base au Maroc en 2022. À quand le Chili ?</p><p>Postscriptum : Quand je m’enthousiasme pour une startup dans binaire, il se trouve parfois un de nos très chers lecteurs pour questionner mon objectivité, m’accuser d’avoir des amis dans la startup, d’y avoir investi, voire de me faire payer pour la pub. Et bien non rien de tout cela. J’ai trouvé que c’était une idée géniale et j’ai voulu la raconter.</p><p><a href="https://fr.wikipedia.org/wiki/Serge_Abiteboul">Serge Abiteboul</a>, Inria et ENS, Paris</p><hr/><p><strong>[1]</strong> Sorbonne Université est une université française située à Paris. Elle a été créée le 1er janvier 2018 par regroupement des universités Paris-Sorbonne (Paris-IV) et Pierre-et-Marie-Curie (Paris-VI), elles-mêmes créées en 1970 et héritières de l’université de Paris fondée en 1896.</p><p><strong>[2]</strong> Serge Abiteboul, François Bancilhon, François Bourdoncle, Stephan Clemencon, Colin De La Higuera, et al. L’émergence d’une nouvelle filière de formation : data scientists », 2014 <a href="https://hal.inria.fr/hal-01092062">https://hal.inria.fr/hal-01092062</a></p>]]></content>
        <author>
            <name>Serge Abiteboul</name>
            <uri>https://www.inria.fr/fr/serge-abiteboul-1</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Classification des mains de scribes assistée par l’intelligence artificielle]]></title>
        <id>egyptologie</id>
        <link href="https://datacraft-paris.github.io/blog/egyptologie"/>
        <updated>2021-03-04T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Article publié dans Archeologia Magazine le 04/03/2021]]></summary>
        <content type="html"><![CDATA[<p>Cet article a été initialement publié le 04/03/2021 dans <a href="https://www.archeologia-magazine.com/numero-596/egypte-dernieres-decouvertes/egypte-dernieres-decouvertes.53184.php#article_53184">Archeologia Magazine</a>, magazine payant d&#x27;archéologie.</p><p>.</p><p><strong>Mettre les images avec les légendes.</strong></p><p>.</p><hr/><h1>CLASSIFICATION DES MAINS DE SCRIBES ASSISTÉE PAR L’INTELLIGENCE ARTIFICIELLE</h1><p><strong>Depuis 2019, L’Ifao et Sorbonne Université mènent conjointement un programme de recherches (ÉCRITURES – Pour une archéologie et une anthropologie des écritures de l’Égypte ancienne) afin de mieux comprendre les usages des différentes graphies égyptiennes et les acteurs impliqués. Si les textes de la vie courante (administration, lettres, littérature, sciences, textes magiques et rituels) étaient inscrits en hiératique, l’écriture principale des scribes égyptiens, une cursive dérivée des hiéroglyphes, ces derniers demeuraient limités à des usages monumentaux et sacrés.</strong></p><img width="33%" src="https://raw.githubusercontent.com/blog/img/2021-03-04-Egyptologie/Ostracon-IFAO_117.jpg"/><p><img src="img/2021-03-04-Egyptologie/Ostracon-IFAO_117.jpg?raw=true" width="200"/></p><p><img src="./img/2021-03-04-Egyptologie/Ostracon-IFAO_117.jpg" alt="Annotation de l’ostracon IFAO 117" title="Annotation de l’ostracon IFAO 117"/></p><div style="text-align:center;margin-left:9em;margin-right:9em;margin-bottom:5em"> Exemple de signes annotés sur l’ostracon IFAO 117 rédigé de la main du scribe Amennakhte. © Ifao.</div><h1>Identifier les mains pour connaître les lettrés</h1><p>Les scribes, les auteurs et plus généralement les praticiens de l’écriture en Égypte ancienne, restent mal connus d’autant que leurs manuscrits sur papyrus ou sur ostraca (tessons de poterie ou morceaux de calcaire taillés inscrits) furent le plus souvent anonymes. Une des tâches des égyptologues consiste donc à examiner les styles individuels d’écriture pour rapprocher entre eux des documents issus d’une même main. Les outils de la paléographie aident à établir des comparaisons entre la forme de certains signes afin de regrouper des textes possiblement tracés par une même personne. Mais les caractéristiques à prendre en compte sont nombreuses (forme générale du signe, nombre de traits, taille, dynamisme de l’écriture, mise en page, régularité...) et constituent autant d’aspects difficiles à combiner et à comparer, pour l’œil et l’esprit humains, lorsque le nombre de documents se multiplie. </p><h1>L&#x27;apport du Deep Learning</h1><p>C’est là que les outils d’intelligence artificielle, habilement mis en œuvre, peuvent s’avérer décisifs. Ce programme de recherche s’est donc associé au Sorbonne Centre of Artificial Intelligence et à datacraft afin explorer les solutions que le deep learning (ou réseau de neurones) peut apporter. Une première</p><p>expérience a ainsi été montée à partir de documents de scribes de l’époque ramesside (XIII e -XI e siècles avant notre ère). Des jeux de données provenant du British Museum, du Museo Egizio de Turin et de l’Institut français d’archéologie orientale, constitués de photos numériques d’ostraca et de papyrus publiés, ont été collectés. Réalisée avec l’équipe Data science de Vinci Autoroutes qui travaille régulièrement avec datacraft, une étape de préparation des données a été nécessaire avant de présenter ces images numériques au réseau de neurones. Grâce au logiciel de Vinci, les égyptologues ont annoté les documents dont les scribes-rédacteurs étaient connus avec certitude. Il fut ensuite possible de classer automatiquement les images non-annotées grâce au réseau de neurones, ce dernier identifiant si telle ou telle image appartient à une main déjà connue. Une autre voie explorée se fonde plus directement sur les signes égyptiens utilisés dans les documents non classés. Elle consiste à utiliser le réseau de neurones pour regrouper les textes dont les signes d’une écriture similaire, ce qui permettra à terme d’identifier de nouveaux scribes potentiels…</p><p><strong>Chloé Ragazzoli</strong>, Sorbonne Université, <strong>Florence Albert</strong>, Ifao, <strong>Xavier Lioneton</strong>, datacraft, <strong>Amir Nakib</strong>, Vinci, dans le cadre d’une collaboration au sein du club datacraft</p>]]></content>
        <author>
            <name>Chloé Ragazzoli - Florence Albert - Amir Nakib - Xavier Lioneton</name>
            <uri>https://datacraft.paris/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[datacraft - un club dédié à la data science et l’Intelligence Artificielle]]></title>
        <id>datacraft</id>
        <link href="https://datacraft-paris.github.io/blog/datacraft"/>
        <updated>2021-02-15T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Article publié dans Visionary le 15/02/2021]]></summary>
        <content type="html"><![CDATA[<p>Cet article a été initialement publié le 15/02/2021 dans <a href="https://visionarymarketing.com/fr/2021/02/datacraft-data-science-et-ia/?mc_cid=a430616615&amp;mc_eid=0bd4a33d6d">Visionary</a>, site d&#x27;infos des marketeurs et innovateurs visionnaires depuis 1996.</p><p>.</p><p>.</p><p>.</p><p><strong>Job : Voir si possible d&#x27;inclure l&#x27;audio de l&#x27;interview d&#x27;Isabelle.</strong></p><p>.</p><p>.</p><p>.</p><hr/><h1>Datacraft : un club dédié à la data science et l’Intelligence Artificielle</h1><p>Un club Data Science et IA ? Là où beaucoup veulent absolument qu’on remplace les humains par des robots, les experts de l’IA démontrent la supériorité des échanges humains. Car il y avait un besoin d’échange dans la communauté de la data science et <a href="https://www.linkedin.com/in/isabelle-hilali-82b5111/">Isabelle Hilali</a>, CEO et fondatrice de Datacraft, que <a href="https://visionarymarketing.com/fr/2016/09/big-data-sante-combinaison-necessaire/">nous avions déjà interviewée</a> ici il y a quelques années, l’avait pressenti. Elle n’a pas hésité à lancer son club data science en plein milieu de la crise du Covid et a démontré, même en ces temps difficiles que tout est possible. Elle a démontré également que la nécessité de se parler, y compris pour les experts de l’IA et de la data science, est plus forte que jamais. Retour sur la création d’un club hors du commun, où se dessine collaborativement le futur de vos logiciels. </p><h2>Datacraft : un club data science et IA installé au cœur de La Sorbonne</h2><p><img src="./img/2021-02-15-datacraft/datacraft-scai.png" alt="Dans les locaux de datacraft" title="Dans les locaux de datacraft"/></p><div style="text-align:center;margin-left:9em;margin-right:9em;margin-bottom:5em"> Yann Gourvennec a rencontré Isabelle Hilali dans les locaux du SCAI (Sorbonne Center for Artificial Intelligence) qui héberge datacraft, le club de la data science et de l’IA qu’elle a créé</div><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;J’ai observé que l’univers de la data science et des data scientists est un domaine sur lequel il faut apprendre tout le temps et où tout va extrêmement vite.&quot;</div><p style="color:#000000;margin-right:1em;text-align:right"> <b>- Isabelle Hilali – Datacraft</b> </p></div><p>« En data science, il est vraiment compliqué d’être à la pointe en termes de compétences. C’est un univers où l’on a besoin de partager. On a toujours l’image du geek qui est seul derrière son micro, mais en fait, si on veut être bon, il faut croiser les données et être imaginatif » explique Isabelle.</p><p>C’est un univers sur lequel il y a beaucoup de liberté puisque ce sont des métiers très demandés alors que trop peu de bonnes compétences sont disponibles. Les data scientists peuvent donc quelque peu « imposer » la façon dont ils ont envie de travailler. Et ils ont envie de travailler de manière flexible.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;L’idée, c’était d’avoir un lieu qui donne envie de collaborer&quot;</div></div><p>Le Centre d’intelligence artificielle de la Sorbonne a été imaginé pour permettre de se retrouver pour collaborer. C’est un lieu ouvert. Et c’est là que Datacraft s’est implanté, entre la tour de Jussieu et le jardin des plantes.</p><iframe width="85%" height="500px" src="https://www.youtube.com/embed/0xtPrTo-13o" alt="Présentation de datacraft par Isabelle" title="YouTube video player" frameBorder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><h2>Un portrait robot du data scientist ? Impossible tant ce mot recouvre des réalités différentes</h2><p>J’aimerais bien faire un portrait robot de la <a href="https://visionarymarketing.com/fr/2015/07/data-scientist/">data scientist</a>, mais il n’y en a pas beaucoup pour l’instant … Alors j’ai commencé par le data scientist au sens large.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;Il n’y a pas de portrait robot du data scientist. Ce mot est utilisé un peu à tort et à travers. Il recouvre différentes réalités&quot;</div></div><p>Il y a également le data ingénieur, le data scientist, le data analyst. Il y a besoin de préparer les données, de développer des modèles, d’intégrer aussi tout cela dans le système d’information.</p><p>Certains ont une formation assez classique, une grande école d’ingénieurs ou une grande école de math et d’informatique. Mais d’autres ont fait de la musique et ensuite se sont formés à la datascience.</p><p><img src="./img/2021-02-15-datacraft/un_atelier.webp" alt="datacraft pendant un atelier" title="datacraft pendant un atelier"/></p><div style="text-align:center;margin-left:9em;margin-right:9em;margin-bottom:5em"> Même masqués, les ateliers datacraft de data science sont un moment privilégié d’échange et de travail</div><p>Le bon data scientist, qui va être performant dans une organisation, doit être curieux. Il doit être ouvert à l’organisation dans laquelle il est, pour comprendre la situation et éviter de construire des modèles abstraits qui ne serviront à rien. Il doit comprendre les problématiques en allant chercher des données, en faisant de l’apprentissage machine, en développant des modèles, en s’interrogeant sur la meilleure façon d’aider à la connaissance, à la prise de décision.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;Pour moi, le bon data scientist est quelqu’un d’ouvert et de collaboratif, et qui a des compétences en mathématiques et en informatique, ou au moins la capacité à travailler sur ces sujets&quot;</div></div><h2>La nécessité d’apprendre dans le domaine de la data science</h2><p>Le besoin principal sur lequel j’avais envie de travailler, était la nécessité d’apprendre en permanence.</p><p>Il existe bien des formations en ligne, des formations physiques, des livres, des communautés pour faire de la recherche. Mais il n’existait pas de lieu physique où partager les choses.</p><p><strong>J’ai été assez inspirée par le modèle du compagnonnage</strong>, c’est une chouette façon d’apprendre, avec les autres, en le revisitant un peu, car dans notre modèle, chacun apprend aux autres, il n’y a pas de maître ni d’élève. Chacun est maître sur un bout de sujet.</p><p>Je me suis dit qu’il faudrait qu’il y ait des lieux qui permettent aux gens un échange de bonnes pratiques et qui soient pensés pour ça. Et en même temps qui développent la collaboration et la réflexion sur ce qu’on fait, quelles limites on veut donner quand on développe de l’intelligence artificielle.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;Notre volonté avec Datacraft était de créer ce réseau de lieux pour se retrouver entre experts pour un échange de bonnes pratiques&quot;</div></div><h2>Le lancement de Datacraft, le club data science et IA</h2><p>J’ai lancé DataCraft en janvier 2020, avec le groupe Accor et l’Insep, les deux premiers membres qui m’ont fait confiance, et dans de supers locaux dans le Marais.</p><p>Tout cela a pris forme début février avec l’ouverture des locaux, avec également notre système de résidence où l’on accueille à la fois des chercheurs, et des freelances qui font partie de la communauté, qui ne paient pas d’adhésion, mais qui donnent du temps à la communauté.</p><p>Et puis tout a fermé un mois plus tard avec le confinement …</p><p>Le concept étant de mettre les gens ensemble et d’avoir cette complémentarité avec ce qui existe en digital, j’ai pensé qu’il allait falloir fermer.</p><p>Et puis finalement, on avait encore davantage besoin de cet échange de bonnes pratiques, de cette solidarité entre experts et de cette créativité.</p><p>La communauté a énormément grossi. Nous sommes passés de 80 a plus de 500 en fin de confinement, en fédérant des gens qui avaient envie de s’entraider.</p><h2>Un club data science : comment ça marche ?</h2><p>Par exemple, un membre va communiquer sur le développement d’une application en Python, alors qu’il a l’habitude de faire sur <a href="https://help.adobe.com/en_US/air/build/index.html">Adobe Air</a>, et poser la question si d’autres membres ont déjà fait cela pour un type d’applications, pour un tableau de bord par exemple.</p><p>La demande est lancée dans la communauté, des membres vont répondre et au lieu que ce soit deux personnes qui se parlent, on en profite pour organiser un atelier, virtuellement pendant le Covid, où les gens vont partager leurs bonnes pratiques. Souvent, à la fin de l’atelier, un atelier suivant se dessine de par les échanges qui ont eu lieu sur par exemple une bibliothèque que les membres n’avaient jamais pensé à utiliser comme ça.</p><p>Puis, il y a eu le premier déconfinement et nous avons recommencé à faire des ateliers en physique.</p><p>Nous avons organisé un atelier, par exemple, sur les données du sport de haut niveau, avec des problématiques telles qu’aider un entraîneur à optimiser son équipe, à choisir l’équipe qui sera la plus performante en fonction des adversaires, en fonction de données, de météo ou de tout cet environnement.</p><p>C’est un prétexte. Sur un projet comme ça, des membres vont venir pendant deux jours travailler ensemble, des gens de l’Insep, de Vinci Autoroutes, d’un labo pharmaceutique, d’une petite startup qui va travailler sur des données des réseaux sociaux, par exemple. Et tous ces gens vont travailler ensemble pendant deux jours.</p><p>Contrairement à un hackathon, notre objectif n’est pas de faire un prototype au bout de deux jours qui souvent, en outre, n’est pas très bon.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;Notre seule volonté est qu’à la fin des deux jours ou de la demi-journée, les participants repartent en se disant  » C’est génial, j’ai appris telle chose »&quot;</div></div><p>C’est ça notre objectif, un échange de bonnes pratiques, où même les « super experts » apprennent quelque chose.</p><p>Cela va bien au delà bien sûr. De nombreux partenariats se nouent, qu’on n’aurait jamais imaginé. Un partenariat entre Vinci Autoroutes et le sport de haut niveau par exemple.</p><p>Ou encore une startup qui travaille sur les données des réseaux sociaux en santé, qui va découvrir une expertise complémentaire chez un membre de Datacraft, et envisager de monter un gros projet européen sur les fakenews médicales.</p><p>Ou encore Danone, par exemple, qui est en train de rédiger sa <a href="https://visionarymarketing.com/fr/glossaire/marketing-ethique/">charte</a> sur l’utilisation responsable des données, qui la réalise avec d’autres membres qui l’ont déjà fait pour l’écrire ensemble.</p><h2>L’avenir pour Datacraft, le club de la data science</h2><p>L’idée était d’avoir un lieu qui donne envie de collaborer et de se poser des questions sur la façon dont on travaille la data, quelle responsabilité on a envers la société.</p><p>L’idée était aussi d’avoir dans Paris un lieu avec un jardin, des plantes, qui favorise cette collaboration et cette réflexion.</p><p>Nous sommes au Centre d’intelligence artificielle de la Sorbonne, et cela fait énormément de sens. Le Centre d’intelligence artificielle de la Sorbonne a été imaginé pour permettre à tout l’écosystème de Sorbonne universités, le Museum d’histoire naturelle, l’IRCAM en musique, la fac de médecine, de se retrouver pour collaborer.</p><p>C’est un lieu ouvert où les entreprises sont les bienvenues. Etre hébergés ici, à côté du Jardin des Plantes, est complètement en phase avec nos valeurs.</p><p><strong>Dans le futur, il y aura d’autres bases datacraft</strong> qui seront toutes imaginées autour de ce concept de collaboration et de responsabilité.</p><h2>Le Covid : crise ou opportunité ?</h2><p>Cela a été aussi une source de créativité pour nous, Cela nous a permis de faire des choses à distance, et d’avoir, par exemple, des personnes en Ouganda qui nous ont demandé de participer à un atelier. Nous n’aurions pas pu faire ce genre de choses aussi rapidement.</p><p>Et puis, ça nous a montré ce besoin de solidarité et d’échange de bonnes pratiques.</p><div style="margin-top:1em;margin-left:9em;margin-right:9em;margin-bottom:1em"><div class="warning" style="font-size:16px;background-color:#CCCCCC;color:#000000;border-left:solid #FF3300 2px;padding:0.8em"> &quot;Même si on espère bien sûr que ça durera pas trop longtemps, cette période a finalement encore renforcé nos valeurs&quot;</div></div>]]></content>
        <author>
            <name>Yann Gourvennec</name>
            <uri>https://visionarymarketing.com/fr/author/yann-gourvennec/</uri>
        </author>
    </entry>
</feed>